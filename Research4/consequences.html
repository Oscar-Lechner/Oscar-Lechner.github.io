<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CONSEQUENCES</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <h1> AI IN THE COURTROOM</h1> 

        <nav>
            <ul>
                <br>
                <li><a href="https://alyssacady.me/Research4/homepage4.html">HOME</a></li> 
                <li><a href="https://alyssacady.me/Research4/background.html">BACKGROUND</a></li>
                <li><a href="consequences.html">CONSEQUENCES</a></li>
                <li><a href="solutions.html">SOLUTIONS</a></li>
            </ul>
        </nav> 

        <h2>UNINTENDED CONSEQUENCES</h2>
        <p>Despite their objective and artificial nature, AI judges can still be biased. <br>
            An AI model is only as good as the data it is trained on.
        </p>
        
        <article>
            <div id ="no1">
                <h3>Racial and Gender Bias:</h3>
                <h4> 
                    - AI-driven assessment tools, such as COMPAS, can inadvertently perpetuate racial and socioeconomic biases. For example, a report by the National Institute of Standards and Technology found that facial recognition algorithms used by police created more false positive results when evaluating images of Black women. <br>
                    - Predictive policing applications, such as PredPol, may be tainted by being trained on "dirty data." This refers to historical data that includes biases or errors, such as arrest records and police reports that have not been cleaned or corrected for documented violations. As a result, AI systems trained on this data may lead to excessive or insufficient deployment of police resources to the same communities that were the subject of the tainted data. <br>
                    - There have been concerns about their accuracy and fairness. For example, a study by ProPublica found that the COMPAS tool falsely flagged Black defendants as future criminals at almost twice the rate of white defendants, highlighting potential racial bias in the algorithm.
                </h4>
            </div> </article>

        <article>
            <div id ="no1">
                <h3>Racial and gender bias:</h3>
                <h4> - a report by the National Institute of Standards and Technology found that facial recognition algorithms used by police created more false positive results when evaluating images of Black women <br>
                    - Communication between judicial personnel <br>
                    - Allocation of resources and cases <br>
                    - Score offenders risk of reoffending <br>
                    - Recommends alternative punishment to <br>
                    &nbsp;&nbsp;low risk people <br>
                    - Ensures anonymisation of <br>
                    &nbsp;&nbsp;decisions / documents / data <br>
                    <img src ="ai.jpg" src ="ai"> 
                    </h4>
            </div> 

            <div id ="no2">
                <h3>PROS:</h3>
                <h4> - AI lowers the administrative burden of cases<br> 
                    - Increase court efficiency / reduce backlog of cases<br>  
                    - Allows for standardized outcomes <br>
                    - Lower costs <br>
                    - More accessible to people who cannot afford lawyers <br>
                    - Improves fairness by:<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;following strict precedents <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;prevent personal bias<br> 
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;handle large amounts of information <br>
                    - Can be used to help judges find relevant legal provisions and <br> 
                    thorough data retrieval which can improve judges understanding<br> 
                    and avoid one sided access to data <br> 
                    - Significantly increase the probability of offering alternative punishment <br> 
                    - Decrease probability of incarceration <br> 
                    - Shortens length of imprisonment <br> 
                    
                     <img src ="aiBOT.png" src ="ai robot"> 
                </h4>
            </div> 

            <div id ="no3">
                <h3>CONS:</h3>
                <h4> - Allocation of cases to a specific judge based on<br>
                    &nbsp;&nbsp;&nbsp;expertise / bias could indirectly influence outcome<br> 
                    - AI can perpetuate discrimination if allowed
                    <img src ="court.jpeg" src ="court room"> 
               </h4>
            </div> 
        </article>

        <h5>AI SENTENCING:</h5>
        <p>AI calculates risk of repeat offense 
            People who AI deemed low-risk offenders <br><br>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -> 16% lower incarceration for drug crimes <br>
            ->11% lower incarceration for fraud<br>
            &nbsp;&nbsp;->6% lower incarceration for larceny <br><br>
            Decreases financial burden of states with high incarceration costs <br>
             AI decreased jail sentences by an average of 1 month <br>
             AI sentencing advice makes it less likely for offenders to be back in jail <br>
            Following AI sentencing recommendations reduces incarceration and recidivism <br>
            </p>


        <article2>
                <div id ="no1">
                    <h3>RACIAL BIAS</h3>
                        <h4> - Sentenced high-risk White and Black defendants equally <br> 
                            &nbsp;&nbsp;based on risk scores <br>
                            - When AI recommended probation for low-risk offenders<br>
                            &nbsp;&nbsp;judges disproportionally declined to offer alternative to <br> 
                            &nbsp;&nbsp;incarceration for Black defendants. <br> 
                            - Black defendants were given significantly lower alternative punishments <br>
                            &nbsp;&nbsp;and longer jail terms than White counterparts    
                        </h4>
                        <img src ="jail.png" src ="man in jail "> 
                </div> 
    
                <div id ="no2">
                    <h3>GENDER BIAS</h3>
                        <h4> Typically judges sentence females more leniently than males <br>
                            &nbsp;&nbsp; - AI helped reduce gender bias 
                        </h4>
                            
                            
                            <img src ="mw.jpeg" src ="man woman on scale"> 
                        </h4>
                </div> 
                </div> 
           
        </article2>    
</body>
</html>